\documentclass[titlepage]{article}

\usepackage{preamble}

\title{
    \textbf{ANALYSIS OF \\
    MACHINE LEARNING \\
    APPLIED TO BOARD GAMES}
}

\author{
    \rule{8cm}{0.3mm} \\[1.3cm] 
    \small \scshape{Adam Amanbaev, Jonathan Hallström, Alvar Edvardsson} \\ 
    \small \scshape{Hugo Åkerfeldt, Romeo Patzer} \\[1cm]
    \small \scshape{Supervisor: Ulf Backlund}
}

\begin{document}

\maketitle

\newpage

\begin{abstract}
In October 2022 DeepMind announced an artificial intelligence in a preprint \cite{alphazero} that was called AlphaTensor. It utilized \emph{artificial neural networks} in combination with \emph{heuristic algorithms} in order to solve the unsolved problem of finding faster algorithms for matrix multiplication. AlphaTensor was succesful and has shed light on the process of finding new algorithms. In this paper we aim to study the effectiveness of different \emph{neural networks} and \emph{heuristic algorithms} such as the one used in AlphaTensor. More precisely, we intend to analyze the efficiency of those networks and algorithms in combination with varying \emph{optimizations, parameters, hyperparameters} and \emph {architectures} applied to the classic games \emph{Connect Four} and \emph{Othello}. 

\vskip 1cm

\keywords{Machine Learning, Supervised Learning, Reinforcement Learning, Neural Network, Deep Learning} 

\end{abstract} 

\pagenumbering{roman}

\tableofcontents

\newpage 

\section*{Preface}
\addcontentsline{toc}{section}{Preface}

\newpage

\section*{\huge Summary of Notation}
\addcontentsline{toc}{section}{Summary of Notation}

\vskip 0.5cm

\epigraph{
I am a forest, and a night of dark trees: but he who is not afraid of my darkness, will find banks full of roses under my cypresses.
\attr{Friedrich Nietzsche, Thus Spoke Zarathustra}
}

\vskip -1cm

\nomenclature{$\argmin_x f(x)$}{\{$x \mid f(x) = \min_{x'} f(x')$\}}
\nomenclature{$\argmax_x f(x)$}{\{$x \mid f(x) = \max_{x'} f(x')$\}}
\nomenclature{$\leftarrow$}{assignment}
\nomenclature{$P(a \mid b)$}{probability of a given b}

\printnomenclature[3cm]

\newpage

\clearpage
\pagenumbering{arabic}

\newpage

\subsection{Background}
\subsection{Analysis}

\newpage

\section{Games}
\subsection{Connect Four}
\subsection{Othello}

\newpage

\section{Deep Learning}

\subsection{Introduction}

\newpage

\subsection{Basic Architecture of Neural Networks}
\subsubsection{Perceptron}
\subsubsection{Fully Connected Neural Network}

\newpage

\subsection{Backpropagation}
\subsubsection{Gradient Descent}
\subsubsection{Loss Function}

\newpage

\subsection{Complications with Neural Network Training}
\subsubsection{Overfitting}
\subsubsection{Vanishing and Exploding Gradient}
\subsubsection{Difficulties in Convergence}
\subsubsection{Local Optima}
\subsubsection{Computational Challenges}

\newpage

\subsection{Training Neural Networks}
\subsubsection{Backpropagation in Detail}
\subsubsection{Preventing Extreme Gradients}
\subsubsection{Gradient Descent Strategies}

\newpage

\subsection{Generalizing Neural Networks}

\newpage

\subsection{Convolutional Neural Network}
\subsubsection{Historical Background}
\subsubsection{Architecture of a Convolutional Network}
\subsubsection{Training a Convolutional Network}
\subsubsection{Applications of Convolutional Networks}

\newpage

\section{Reinforcement Learning}

\newpage

\subsection{Introduction}

\newpage

\subsection{Monte Carlo Tree Search}
\subsubsection{Upper Confidence Bound}

\newpage

\section{Heuristic Algorithms}
\subsection{MiniMax}

\newpage

\bibliographystyle{plain}
\bibliography{refs}

\end{document}
