% define class of document
\documentclass[titlepage]{article}

% packages
\usepackage[cmintegrals,cmbraces]{newtxmath}
\usepackage{ebgaramond-maths}
\usepackage[T1]{fontenc}
\usepackage{hyperref}

\newcommand{\newpara} {
    \vskip 0.4cm
    \noindent
}

% title
\title{
    \textbf{ANALYSIS OF \\
    MACHINE LEARNING \\
    APPLIED TO BOARD GAMES}
}

% author and supervisors
\author{
    \rule{8cm}{0.3mm} \\[0.5in] 
    \textit{Adam Amanbaev, Jonathan Hallström, Alvar Edvardsson} \\
    \textit{Romeo Patzer, Hugo Åkerfeldt} \\\\
    \small \textit{Supervisor: Ulf Backlund}
}
% date-specification
\date{}

% begin document
\begin{document}

% create the title and authors
\maketitle

% new page
\newpage
\noindent
\textbf{WORKPLAN} 
\newpara
Reinforcement learning consists of an agent that learns a policy-function with a goal in mind.
It takes in a state, which in our case is a state of the game connect four, and with a policy-function decides a move to make.
With a goal in mind various algorithms are implemented in order to improve the policy-function which improves the decision-making.
The goals in our case are maximizing some set of heuristics such as losing and winning, respectively. \\\\
In addition, reinforcement learning can be applied to data-structures known as neural networks.
These self-learning neural networks intend to simulate biologal neural networks but with the help of computional power. \\\\
We intend to implement several neural networks with varying algorithms, parameters, hyperparameters and archictures.
They will further on be put up against eachother and themselves which will allow an analysis of their differences in effectiveness.
Different combinations of these networks and methods of learning will be compared to eachother and provide insights in their impact on efficiency of learning, decision making and quality of learning. \\\\
\textbf{Topics of interest:} \\\\
1. How effective is Q-Learning by itself \\\\
2. How effective is a genetic algorithm by itself? \\\\
3. How effective are convolutional neural networks by themselves? \\\\
4. How does the order of training (against heuristical algorithms, themselves, other neural networks) affect performance? \\\\
5. How well do the neural networks perform against eachother and heuristical algorithms? \\\\
6. How effective are different combinations of learning-methods? \\\\
This work is limited to the game connect four, possibly a variation of it and a few neural networks with varying architectures. \\\\
In order to collect data to be analyzed, we will implement everything in the programming language C++ and conduct several experiments.
Each evaluation will be based on numerous games, after their training, that will give us respective approximate probabilities of winning for each network.
Other aspects are also going to be studied such as learning rate and speed of decision making.
All data will be generated by us and our written code. 

\newpage
\noindent
We will expand our knowledge of machine learning and implement everything in C++.
Different algorithms and neural networks will be assigned throughout the group depending on individual wishes. \\\\
Since all of us are interested in programming and the topic, we constantly work on the project.
It is therefore neither fully necessary nor helpful to assign strict deadlines.
Bertil Lundell, teacher in programming, checks on our progress every other week in order to keep our process going.
We intend to be finished with 2 to 3 different neural networks until the 2nd December when half of the work should be submitted. \\\\
\textbf{Preliminary work distribution:} \\\\
Hugo Åkerfeldt: Heuristical Algorithms \\\\
Alvar Edvardsson: Deep Q-learning 
Jonathan Hallström: Deep Q-learning \\\\
Adam Amanbaev: Convolutional Neural Network / Heuristic Algorithms \\\\
Romeo Patzer: Heuristic Algorithms \\\\

% references
\begin{thebibliography}{100}
\bibitem{book1}
Sutton, R. S., Barto, A. G., Reinforcement Learning: An Introduction
\bibitem{book2}
Introduction to Deep Learning: from Logical Calculus to Artificial Intelligence, Springer,
London, 2018.
\end{thebibliography}
\end{document}
